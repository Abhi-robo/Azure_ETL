{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82c99eea-743d-4c9b-9b41-c1dbdec5a44f",
     "showTitle": true,
     "title": "Mounting Raw container"
    }
   },
   "outputs": [],
   "source": [
    "def mounting_raw():\n",
    "    dbutils.fs.mount(\n",
    "        source=\"wasbs://raw@pracpipeline.blob.core.windows.net\",\n",
    "        mount_point='/mnt/raw',\n",
    "        extra_configs = {\n",
    "            \"fs.azure.account.key.pracpipeline.blob.core.windows.net\": \"8DmFEfAaT2VoAD2oFUhEeDOs6NQEsUNlyYjg6LzA5TYEcwQhTD+JEr5d5LwVDjZwMlD7/Pe8xH2P+AStwJ5tQA==\"\n",
    "        }\n",
    "    )\n",
    "try:\n",
    "    mounting_raw()\n",
    "except Exception as e:\n",
    "    print(\"Raw Container already mounted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6c7e7a8-9be7-4b70-bbf2-e65f8b05b149",
     "showTitle": true,
     "title": "Mounting integrated container"
    }
   },
   "outputs": [],
   "source": [
    "def mounting_integrated():\n",
    "    dbutils.fs.mount(\n",
    "        source=\"wasbs://integrated@pracpipeline.blob.core.windows.net\",\n",
    "        mount_point='/mnt/integrated',\n",
    "        extra_configs = {\n",
    "            \"fs.azure.account.key.pracpipeline.blob.core.windows.net\": \"8DmFEfAaT2VoAD2oFUhEeDOs6NQEsUNlyYjg6LzA5TYEcwQhTD+JEr5d5LwVDjZwMlD7/Pe8xH2P+AStwJ5tQA==\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "try:\n",
    "    mounting_integrated()\n",
    "except Exception as e:\n",
    "    print(\"Integrated Container already mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abbbf8be-4896-4c2a-b0f7-f7231f799fa4",
     "showTitle": true,
     "title": "Initializing variables"
    }
   },
   "outputs": [],
   "source": [
    "records_read=0\n",
    "record_inserted=0\n",
    "df=\"\"\n",
    "system_id = 1\n",
    "new_aggdata=\"\"\n",
    "trigged_by = dbutils.notebook.entry_point.getDbutils().notebook().getContext().userName().get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88560a8b-146b-48ca-8f66-26ae3da37a1d",
     "showTitle": true,
     "title": "Checking whether the inputs is present in seed_table"
    }
   },
   "outputs": [],
   "source": [
    "def check_seed_table(system_id):\n",
    "    system_id=int(system_id)\n",
    "    qury=\"select * from spark_catalog.bcp_control.tb_system_seed where System_Id=\"+str(system_id)\n",
    "    print(qury)\n",
    "    systemdf= spark.sql(qury)\n",
    "    if(systemdf.count()==0):\n",
    "        raise Exception(\"Data not present\")\n",
    "    return systemdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9f24c24-91ac-43d6-a0ff-325b364178e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    systemdf=check_seed_table(system_id)\n",
    "    source_db = systemdf.collect()[0].Source_DB\n",
    "    source_type = systemdf.collect()[0].Source_Type\n",
    "    source_object_name = systemdf.collect()[0].Source_Object_Name\n",
    "    target_type = systemdf.collect()[0].Target_Type\n",
    "    target_db = systemdf.collect()[0].Target_DB\n",
    "    target_object_name = systemdf.collect()[0].Target_Object_Name\n",
    "    application_name = systemdf.collect()[0].Application_Name\n",
    "    isDelta=systemdf.collect()[0].IsDelta\n",
    "    deltaField=systemdf.collect()[0].Delta_Field\n",
    "    display(systemdf)\n",
    "except Exception as e:\n",
    "    exp=str(e)\n",
    "    my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":exp,\"system_id\":system_id}\n",
    "    dbutils.notebook.exit(my_json)\n",
    "\n",
    "print(deltaField)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a8a3bd91-362e-4746-aa36-bffd4487c613",
     "showTitle": true,
     "title": "Reading file"
    }
   },
   "outputs": [],
   "source": [
    "#reading file from data lake ie storage account\n",
    "def read_file(path):\n",
    "    return spark.read.format(\"delta\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "323927b9-a2f1-4b73-8265-9c6984be9953",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    path=\"dbfs:/mnt/\"+source_db+\"/\"+source_object_name+\".\"+source_type\n",
    "    df=read_file(path)\n",
    "except Exception as e:\n",
    "    exp=str(e)\n",
    "    my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":exp,\"system_id\":system_id}\n",
    "    dbutils.notebook.exit(my_json)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "277bbb6f-21e2-4b28-9a65-bb9a6b228be2",
     "showTitle": true,
     "title": "full load or incremental load"
    }
   },
   "outputs": [],
   "source": [
    "#funtion to have full load when is delta is false\n",
    "def get_new_data(df):\n",
    "    df.createOrReplaceTempView(\"data\")\n",
    "    return (spark.sql(\"\"\"select * from data\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f45f9f7e-47a8-4181-a20d-9f370cb39146",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    aggdata=get_new_data(df)\n",
    "    records_read=aggdata.count()\n",
    "    record_inserted=aggdata.count()\n",
    "except Exception as e:\n",
    "    exp=\"data not found\"\n",
    "    my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":exp,\"system_id\":system_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "551cdabe-2a79-48ed-b7f2-64e97b9da4fc",
     "showTitle": true,
     "title": "when isDelta is true"
    }
   },
   "outputs": [],
   "source": [
    "def get_old_data(df1):\n",
    "    df1.createOrReplaceTempView(\"data_old\")\n",
    "    qu=\"select * from data_old\"\n",
    "    agg=spark.sql(qu)\n",
    "    return agg\n",
    "def new_data(df,df1,deltaField):\n",
    "    df.createOrReplaceTempView(\"data\")\n",
    "    df1.createOrReplaceTempView(\"data_old\")\n",
    "    qur=\"select * from data where '\"+deltaField+\"' >(select max('\"+deltaField+\"') from data_old)\" \n",
    "    print(qur)\n",
    "    new_aggdata=spark.sql(qur)\n",
    "    return new_aggdata\n",
    "def updated_data(aggdata,new_aggdata):\n",
    "    aggdata=aggdata.unionByName(new_aggdata)\n",
    "    return aggdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8010736e-9c2e-4ac5-937e-18c5e115326b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if(isDelta==True):\n",
    "    try:\n",
    "        path=\"dbfs:/mnt/integrated/\"+target_object_name+\".\"+target_type\n",
    "        df1=read_file(path)\n",
    "        old_data=get_old_data(df1)\n",
    "        delta=deltaField.split(',')\n",
    "        new_aggdata=old_data\n",
    "        print(delta)\n",
    "        for x in delta:\n",
    "            print(x)\n",
    "            new_aggdata=new_data(df,new_aggdata,x)\n",
    "        record_inserted=new_aggdata.count()\n",
    "        aggdata=updated_data(old_data,new_aggdata)\n",
    "    except Exception as e:\n",
    "        exp=str(e)\n",
    "        my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":exp,\"system_id\":system_id}\n",
    "print(record_inserted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1d365ba-6230-48cf-aaad-a0fdc9140eff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "display(aggdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e5ba991-791c-4c80-a4f7-1a50a687e4d0",
     "showTitle": true,
     "title": "Writing data"
    }
   },
   "outputs": [],
   "source": [
    "#writing file into data lake ie storage account as csv\n",
    "def write_file(data,outputpath):\n",
    "    data.write.option(\"header\",\"true\").format(\"delta\").option(\"delta.columnMapping.mode\", \"name\").mode('overwrite').save(outputpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d14ff48-68eb-429f-a1ed-3e3e5680770d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    outputpath=\"dbfs:/mnt/integrated/\"+target_object_name\n",
    "    write_file(aggdata,outputpath)\n",
    "except Exception as e:\n",
    "    exp=str(e)\n",
    "    my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":exp,\"system_id\":system_id}\n",
    "    dbutils.notebook.exit(my_json)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f987052-e962-4f3c-a067-509325046623",
     "showTitle": true,
     "title": "sending json to pipeline into control"
    }
   },
   "outputs": [],
   "source": [
    "my_json={\"records_read\":records_read,\"record_inserted\":record_inserted,\"trigged_by\":trigged_by,\"exception\":'',\"system_id\":system_id}\n",
    "dbutils.notebook.exit(my_json)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Raw to Integrated for Account details",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
