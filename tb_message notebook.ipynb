{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89d85941-b3da-4a3e-a13f-c75f4366a8ad",
     "showTitle": true,
     "title": "Fetching parameters from ADF pipeline"
    }
   },
   "outputs": [],
   "source": [
    "control_id=dbutils.widgets.get(\"control_id\")\n",
    "Error_Code=dbutils.widgets.get(\"Error_Code\")\n",
    "Error_Description=dbutils.widgets.get(\"Error_Description\")\n",
    "control_id=int(control_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51855bbb-c5eb-43fd-ac26-d9141691bf76",
     "showTitle": true,
     "title": "Tb_message Schema"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, LongType\n",
    "schema = StructType([\n",
    "         StructField('Message_Id', LongType(), True),\n",
    "         StructField('Control_Id', LongType(), True),\n",
    "         StructField('Error_Code', StringType(), True),\n",
    "         StructField('Error_Description', StringType(), True),\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ebb24af-c0c5-4f11-92d4-2027a06fb519",
     "showTitle": true,
     "title": "Getting Message_Id"
    }
   },
   "outputs": [],
   "source": [
    "message_id=0\n",
    "try:\n",
    "    message_id=spark.sql(\"select max(Message_Id) from bcp_control.tb_messages\").collect()[0][0]+1\n",
    "except Exception as e:\n",
    "    print(\"NO data avialable\")\n",
    "    message_id=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "822b17b9-5f87-4f5b-a124-94992e8edd65",
     "showTitle": true,
     "title": "Creating dataframe "
    }
   },
   "outputs": [],
   "source": [
    "df=[(message_id,control_id,Error_Code,Error_Description)]\n",
    "df=spark.createDataFrame(df,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f74d5628-aa90-4126-b2c5-8bf29028ea0e",
     "showTitle": true,
     "title": "Inserting logs into tb_message"
    }
   },
   "outputs": [],
   "source": [
    "def insert_data(data,TableName):\n",
    "    data.write.mode(\"append\").saveAsTable(TableName)\n",
    "insert_data(df,\"spark_catalog.bcp_control.tb_messages\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "tb_message notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
